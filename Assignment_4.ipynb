{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                                                 Assignment - 4\n",
    "###       Gauthami\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, cross_val_predict \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing, metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Data analysis, Data Preprocessing and Data Modelling, we have imported all the libraries "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <font color='red'>*Data Preprocessing*</font>\n",
    "\n",
    "\n",
    "### <font color='Blue'>Step1</font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances = 699\n",
      "Number of attributes = 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample code</th>\n",
       "      <th>Clump Thickness</th>\n",
       "      <th>Uniformity of Cell Size</th>\n",
       "      <th>Uniformity of Cell Shape</th>\n",
       "      <th>Marginal Adhesion</th>\n",
       "      <th>Single Epithelial Cell Size</th>\n",
       "      <th>Bare Nuclei</th>\n",
       "      <th>Bland Chromatin</th>\n",
       "      <th>Normal Nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000025</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002945</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1015425</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1016277</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1017023</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sample code  Clump Thickness  Uniformity of Cell Size  \\\n",
       "0      1000025                5                        1   \n",
       "1      1002945                5                        4   \n",
       "2      1015425                3                        1   \n",
       "3      1016277                6                        8   \n",
       "4      1017023                4                        1   \n",
       "\n",
       "   Uniformity of Cell Shape  Marginal Adhesion  Single Epithelial Cell Size  \\\n",
       "0                         1                  1                            2   \n",
       "1                         4                  5                            7   \n",
       "2                         1                  1                            2   \n",
       "3                         8                  1                            3   \n",
       "4                         1                  3                            2   \n",
       "\n",
       "  Bare Nuclei  Bland Chromatin  Normal Nucleoli  Mitoses  Class  \n",
       "0           1                3                1        1      2  \n",
       "1          10                3                2        1      2  \n",
       "2           2                3                1        1      2  \n",
       "3           4                3                7        1      2  \n",
       "4           1                3                1        1      2  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df =  pd.read_csv(r'C:\\Users\\skura\\Desktop\\Classes\\Principles of Data Management and Mining\\Assign4\\breastcancer.csv',delimiter=',',header=None)\n",
    "df.columns = ['Sample code', 'Clump Thickness', 'Uniformity of Cell Size', 'Uniformity of Cell Shape',\n",
    "                'Marginal Adhesion', 'Single Epithelial Cell Size', 'Bare Nuclei', 'Bland Chromatin',\n",
    "                'Normal Nucleoli', 'Mitoses','Class']\n",
    "\n",
    "print('Number of instances = %d' % (df.shape[0]))\n",
    "print('Number of attributes = %d' % (df.shape[1]))\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have loaded up data set into a Pandas DataFrame and assigned column names.Below \n",
    "\n",
    "\n",
    "No of instances = 699\n",
    "\n",
    "No of Attributes = 11\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='purple'>Step2</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances = 699\n",
      "Number of attributes = 10\n",
      "Number of missing values:\n",
      "\tClump Thickness: 0\n",
      "\tUniformity of Cell Size: 0\n",
      "\tUniformity of Cell Shape: 0\n",
      "\tMarginal Adhesion: 0\n",
      "\tSingle Epithelial Cell Size: 0\n",
      "\tBare Nuclei: 16\n",
      "\tBland Chromatin: 0\n",
      "\tNormal Nucleoli: 0\n",
      "\tMitoses: 0\n",
      "\tClass: 0\n",
      "Number of rows in original data = 699\n",
      "Number of rows after discarding missing values = 683\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(['Sample code'],axis=1)\n",
    "df = df.replace('?',np.NaN)\n",
    "\n",
    "print('Number of instances = %d' % (df.shape[0]))\n",
    "print('Number of attributes = %d' % (df.shape[1]))\n",
    "\n",
    "\n",
    "\n",
    "print('Number of missing values:')\n",
    "for col in df.columns:\n",
    "    print('\\t%s: %d' % (col,df[col].isna().sum()))\n",
    "\n",
    "\n",
    "# Missing Value  in attribute\n",
    "print('Number of rows in original data = %d' % (df.shape[0]))\n",
    "data = df.dropna()\n",
    "print('Number of rows after discarding missing values = %d' % (data.shape[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After removing the Sample code solumns, which has no importance as feature to predict the cancer, we also replaced missing values with questions and removed them. There are **16 missing values** in the dataset. After Cleaning data we got following resultshere are 16 instances in Groups 1 to 6 that contain a single missing \n",
    "\n",
    "**Number of rows in original data** = 699\n",
    "\n",
    "**Bare Nuclei** =16\n",
    "\n",
    "**Number of rows after discarding missing values** = 683\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Normalization</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn import preprocessing\n",
    "# Get column names first\n",
    "names = data.columns\n",
    "# Create the Scaler object\n",
    "scaler = preprocessing.StandardScaler()\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "df['Class'] = encoder.fit_transform(df['Class'])\n",
    "X = np.array(data.drop(['Class'], 1))\n",
    "y = np.array(data['Class'])\n",
    "\n",
    "# Fit your data on the scaler object\n",
    "X = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Preprocessing library , we have created a new dataframe that contains the normalized numbers. In order to fit the data into models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# <font color='red'>Random Forest Classifier</font>\n",
    "\n",
    "### Use ensemble.RandomForestClassifier with n_estimators=10 and use K-Fold cross validation to get a measure of the accuracy (K=10). Does it perform better than decision tree?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Random Forest Classifier is :96.64%\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=10, random_state = 36) #Initialize with whatever parameters you want to\n",
    "\n",
    "# 10-Fold Cross validation\n",
    "\n",
    "kf =KFold(n_splits = 10, random_state=30, shuffle=False)\n",
    "RF_accuracy = np.mean(cross_val_score(clf, X, y, cv=kf))\n",
    "\n",
    "\n",
    "\n",
    "print( \"Accuracy for Random Forest Classifier is :{:.2%}\".format(RF_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RandomForestClassifier() from sklearn is a very simple model to build by adding a few parameters to reduce over-fitting. A random forest is a meta estimator that fits a number of decision tree classifiers on various sub-samples of the dataset. Random Forest of **10 decision Trees using K fold cross validation**  to get accuracy of the model which helps determining  whether  breast cancer  is malignant or benign in the class variable.\n",
    "\n",
    "Accuracy for Random Forest Classifier is :**96.64%**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>Decision Tree Classifier using K Fold Cross Validation</font>\n",
    "\n",
    "###  Using  K-Fold cross validation to get a measure of your model’s accuracy (K=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree using K fold Cross Validation :94.74%\n"
     ]
    }
   ],
   "source": [
    "decision = DecisionTreeClassifier(criterion = 'entropy', random_state = 0, max_depth=3)\n",
    "kf =KFold(n_splits = 10, random_state=None, shuffle=False)\n",
    "tree = np.mean(cross_val_score(decision, X, y, cv=kf))\n",
    "\n",
    "\n",
    "\n",
    "print( \"Accuracy of Decision Tree using K fold Cross Validation :{:.2%}\".format(tree))\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy of Decision Tree using K fold Cross Validation : **94.74%**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>Decision Tree Classifier train and Test Split </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree training set accuracy:96.68%\n",
      "Decision tree testing set accuracy:94.15%\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data.loc[:, data.columns != 'Class'],\n",
    "                                                    data['Class'], stratify= data['Class'], random_state=66, test_size = 0.25, train_size = 0.75)\n",
    "\n",
    "tree = DecisionTreeClassifier(max_depth=3, criterion = 'entropy')\n",
    "tree.fit(X_train, y_train)\n",
    " \n",
    "\n",
    "      \n",
    "print(\"Decision tree training set accuracy:{:.2%}\".format(tree.score(X_train, y_train)))\n",
    "print(\"Decision tree testing set accuracy:{:.2%}\".format(tree.score(X_test, y_test)))\n",
    "                                                                    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can create the training and test data, we must remove the ‘id’ column. This column provides no value on the prediction on breast cancer and can be removed with the del function from pandas. Using the **Train_Test_Split** function, we have divided data into **75** of training data  and **25%** of test data.\n",
    "\n",
    "In this DecisionTreeClassifier(), we will add the max_depth parameter which is optional. This parameter sets an integer to the maximum depth of the decision tree. If this left as None, the nodes will be expanded until all leaves are pure or until the leaves contain less than the than min_samples_split samples.\n",
    "\n",
    "\n",
    "Decision tree training set accuracy  :**96.68%**\n",
    "\n",
    "Decision tree testing set accuracy   :**94.15%**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                     <font color='red'>KNN model</font>\n",
    " \n",
    "### Use neighbors.KNeighborsClassifier and use K-Fold cross validation to get a measure of the accuracy (K=10)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9488491048593349, 0.9459505541346974, 0.9590792838874682, 0.9605711849957373, 0.9634271099744247, 0.9634697357203752, 0.9663895993179882, 0.9678601875532824, 0.9663469735720376, 0.9649403239556694, 0.9692881500426258, 0.9663895993179882, 0.9663682864450129, 0.9663895993179882, 0.964919011082694, 0.9634910485933504, 0.9634697357203752, 0.9620204603580564, 0.9634697357203752, 0.9664109121909634, 0.9663895993179882, 0.9649616368286444, 0.9649616368286444, 0.9635123614663257, 0.9649616368286444, 0.9635123614663257, 0.9634910485933503, 0.9649616368286444, 0.9634910485933503, 0.9635123614663257, 0.9620417732310316, 0.9620417732310316, 0.9620417732310316, 0.959143222506394, 0.9605924978687128, 0.9605924978687128, 0.9605924978687128, 0.9605924978687128, 0.9605924978687128, 0.9605924978687128, 0.9605924978687128, 0.959143222506394, 0.959143222506394, 0.959143222506394, 0.9605924978687128, 0.959143222506394, 0.959143222506394, 0.959143222506394, 0.959143222506394]\n",
      "Accuracy for KNeighborsClassifie ne :96.93% At Neighbors = 11\n"
     ]
    }
   ],
   "source": [
    "accuracy =[]\n",
    "\n",
    "k = range(1, 50)\n",
    "\n",
    "for n_neighbors in k:\n",
    "    clf = KNeighborsClassifier(n_neighbors= n_neighbors)\n",
    "    kf =KFold(n_splits = 10, random_state=66, shuffle=False)\n",
    "    knn = np.mean(cross_val_score(clf, X, y, cv=kf))\n",
    "    accuracy.append(knn)\n",
    "    \n",
    "    \n",
    "print(accuracy)\n",
    "\n",
    "#print(\"Max Accuracy  \"+str(max(accuracy))+\"At Neighbors = \"+str(accuracy.index(max(accuracy))+1))\n",
    "\n",
    "\n",
    "\n",
    "print( \"Accuracy for KNeighborsClassifie ne :{:.2%}\".format(max(accuracy)) +\" \" +\"At Neighbors = \"+str(accuracy.index(max(accuracy))+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we have  analyzed the Wisconsin breast cancer dataset for prediction using k-nearest neighbors  algorithm. the algorithm draws a perimeter around K and studies the other data points within that perimeter.\n",
    "\n",
    "From the above results we can view that the nearest **neighbor 11** has the highest  accuracy of **96.93** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>Naive Bayes using K Fold Cross Validation</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Naive Bayes :97.09%\n",
      "Aucroc: 0.873\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "x = np.array(data.drop(['Class'], 1))\n",
    "scale = preprocessing.MinMaxScaler()\n",
    "x = scale.fit_transform(x)\n",
    "kf =KFold(n_splits = 10, random_state=None, shuffle=False)\n",
    "classifier = MultinomialNB()\n",
    "model = classifier.fit(x,y)\n",
    "Naive_Accuracy = np.mean(cross_val_score(model, x, y, cv=kf,scoring='roc_auc'))\n",
    "\n",
    "\n",
    "print( \"Accuracy for Naive Bayes :{:.2%}\".format(Naive_Accuracy))\n",
    "print(\"Aucroc: %0.3f\" % metrics.roc_auc_score(y, cross_val_predict(classifier, x, y, cv=kf)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output for a naive Bayes classifier algorithm consists of a data set placed into a number of different categories. Category composition and the speed of the function can also be determined. There is no further quantitative or qualitative analysis performed. That function can then be repeated again and again in order for machine learning to occur.\n",
    "\n",
    "\n",
    "Accuracy of Naive Bayes is : **97%**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>Conclusion</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are summarised accuracies of Different models\n",
    "\n",
    "Decision tree training set accuracy  :**96.68%**\n",
    "\n",
    "Decision tree testing set accuracy   :**94.15%**\n",
    "\n",
    "Accuracy of Decision Tree using K fold Cross Validation :**94.74%**\n",
    "\n",
    "Accuracy for Random Forest Classifier is :**96.64%**\n",
    "\n",
    "the K Nearest Neighbor 11 has the highest accuracy  **96.93**\n",
    "\n",
    "Accuracy of Naive Bayes is : **97%**\n",
    "\n",
    "\n",
    "**KNN and Naive Bayes**  classfier has the best accuracy compared to other models.We could see that there is no much difference between **Decision Tree**  accuracy and K fold cross validation accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
